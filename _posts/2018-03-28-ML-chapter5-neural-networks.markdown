---
layout:     post
title:      "神经网络"
subtitle:   "《机器学习》 chapter 5"
header-img: "img/post-bg-js-version.jpg"
date:       2018-03-28
author:     "Linzb"
tags:
    - 西瓜书《机器学习》
    - machine learning
---
# 神经网络
人工神经网络（英语：artificial neural network，缩写ANN），简称神经网络（neural network，缩写NN）或类神经网络，在机器学习和认知科学领域，是一种模仿生物神经网络的结构和功能的数学模型或计算模型，用于对函数进行估计或近似。神经网络由大量的人工神经元联结进行计算。大多数情况下人工神经网络能在外界信息的基础上改变内部结构，是一种自适应系统。现代神经网络是一种非线性统计性数据建模工具。典型的神经网络具有以下三个部分：

>- 结构（Architecture）结构指定了网络中的变量和它们的拓扑关系。例如，神经网络中的变量可以是神经元连接的权重（weights）和神经元的激励值（activities of the neurons）。

>- 激励函数（Activity Rule）大部分神经网络模型具有一个短时间尺度的动力学规则，来定义神经元如何根据其他神经元的活动来改变自己的激励值。一般激励函数依赖于网络中的权重（即该网络的参数）。

>- 学习规则（Learning Rule）学习规则指定了网络中的权重如何随着时间推进而调整。这一般被看做是一种长时间尺度的动力学规则。一般情况下，学习规则依赖于神经元的激励值。它也可能依赖于监督者提供的目标值和当前权重的值。例如，用于手写识别的一个神经网络，有一组输入神经元。输入神经元会被输入图像的数据所激发。在激励值被加权并通过一个函数（由网络的设计者确定）后，这些神经元的激励值被传递到其他神经元。这个过程不断重复，直到输出神经元被激发。最后，输出神经元的激励值决定了识别出来的是哪个字母。

神经网络的构筑理念是受到生物神经网络功能的运作启发而产生的。和其他机器学习方法一样，神经网络已经被用于解决各种各样的问题，例如机器视觉和语音识别。这些问题都是很难被传统基于规则的编程所解决的。
## 零、神经元
1943年，基于生物神经网络的麦卡洛克-皮茨神经元模型（McCulloch－Pitts′ neuron model）诞生。它由心理学家Warren McCulloch和数学家Walter Pitts合作提出。M-P神经元模型，也称“阈值逻辑单元”,的基本思想是抽象和简化生物神经元的特征性成分。

McCulloch-Pitts模型公式如下：

![](/img/in-post/2018-03-28-ML-chapter5-mp.png)

阈值b, 亦称bias，如下图，可以看作一个固定输入为1.0的“哑结点”（dummy node)所对应的链接权重b。这样，权重和阈值的学习就可以统一为权重的学习。

神经元示意图：

![](/img/in-post/2018-03-28-ML-chapter5-TLU.png)

```
    a1~an为输入向量的各个分量
    w1~wn为神经元各个突触的权值
    b为偏置
    t为神经元输出

    f为传递函数、激励函数、响应函数，通常为非线性函数。基本作用：
          1、控制输入对输出的激活作用；
          2、对输入、输出进行函数转换；
          3、将可能无限域的输入变换成指定的有限范围内的输出。

```

数学表示  ![](/img/in-post/2018-03-28-ML-chapter5-t.svg)
```
    向量W为权向量,做内积需要用到转置
    向量A为输入向量
    b为偏置（bias），或者称之为阈值（threshold）
    f为传递函数，也即激励函数
```
可见，一个神经元的功能是求得输入向量与权向量的内积后，经一个非线性传递函数得到一个标量结果。

单个神经元的作用：把一个n维向量空间用一个超平面分区成两部分（称之为判断边界），给定一个输入向量，神经元可以判断出这个向量位于超平面的哪一边。




##  一、感知机
感知器（英语：Perceptron）是Frank Rosenblatt在1957年就职于Cornell航空实验室（Cornell Aeronautical Laboratory）时所发明的一种人工神经网络。它可以被视为一种最简单形式的前馈神经网络，是一种二元线性分类器。在人工神经网络领域中，感知机也被指为单层的人工神经网络，以区别于较复杂的多层感知机（Multilayer Perceptron）。作为一种线性分类器，（单层）感知机可说是最简单的前向人工神经网络形式。尽管结构简单，感知机能够学习并解决相当复杂的问题。感知机主要的本质缺陷是它不能处理线性不可分问题。感知器由两层神经元组成，输入层接收外界信号，输出层只有一个McCulloch-Pitts神经元，即阈值逻辑单元，也称为神经网络的一个处理单元( PE，Processing Element )。所以一台感知机只有一个输出，可以有多个输入。如下图：

![](/img/in-post/2018-03-28-ML-chapter5-perceptron.jpg)


很重要的是，这种方法还可以用在多个输出值的函数中，或具有多个类别的分类任务。这对一台感知机来说是不可能完成的，因为它只有一个输出，但是，多输出函数能用位于同一层的多个感知机来学习，每个感知机接收到同一个输入，但分别负责函数的不同输出。

### 感知机损失函数

![](/img/in-post/2018-03-28-ML-chapter5-perceptron-loss.jpg)

### 感知机学习算法

![](/img/in-post/2018-03-28-ML-chapter5-perceptiron-learn.jpg)

感知器是整个神经网络的基础，神经元通过响应函数确定输出，神经元之间通过权值进行传递信息， 权重的确定根据误差来进行调节，这就是学习的过程。这个方法的前提是整个网络是收敛的，1957年罗森布拉特证明了这个结论。

### 线性分类与异或问题

感知器简单而优雅，但它仅对线性问题具有分类能力。什么是线性问题呢？简单来讲，就是用一条直线可分的图形。比如，逻辑“与”和逻辑“或”就是线性问题，我们可以用一条直线来分隔0和1。

逻辑“与”的真值表和二维样本图：

逻辑“或”的真值表和二维样本图：

为什么感知器可以解决线性问题呢？这是由它的权重求和公式决定的。这里以两个输入分量 x1 和 x2 组成的二维空间为例，此时神经元的输出为
o=1,ω1x1+ω2x2−T;
0/-1,ω1x1+ω2x2−T;
0
所以，方程ω1x1+ω2x2−T=0确定的直线就是二维输入样本空间上的一条分界线。

在三维及更高维数的输入样本空间中，ω1x1+ω2x2+...ωnxn−T=0同样表征一个超平面可以划分样本空间。

但是如果要让它来处理非线性的问题，感知器就无能为力了。例如“异或”(XOR，两个输入如果相同，输出为0；两个输入如果是不同，输出为1)，就无法用一条直线来分割开来，因此感知器就没办法实现“异或”的功能。

1969 年，马文·明斯基(Marvin Minsky)和西蒙·派珀特(Seymour Papert)出版了一本书《感知器：计算几何简介》（Perceptrons: An Introduction to Computational Geometry)。书中论证了感知器模型的两个关键问题：其一，单层的神经网络无法解决上面分析的不可线性分割的问题，典型例子如同或（XNOR，两个输入如果相同，输出为1；两个输入如果是不同，输出为0。）其二，受硬件水平的限制，当时的电脑完全没有能力完成神经网络模型所需要的超大的计算量。


## 二、异或问题的解决————多层网络


### 1、多层前馈神经网络：前向传播



### 2、前向传播法

如下图所示，前向传播的思想讲得很清楚了。举个例子，假设上一层结点i,j,k,…等一些结点与本层的结点w有连接，那么结点w的值怎么算呢？就是通过上一层的i,j,k等结点以及对应的连接权值进行加权和运算，结果再加上一个偏置项，然后在通过一个非线性函数f()（即激活函数），如ReLu，sigmoid等函数，最后得到的结果就是本层结点w的输出。
前向传播就是不断的通过这种方法一层层的运算，在输出层结果。

![](/img/in-post/2018-03-16-PCI-chapter4-2-net2.jpg)

其对应的表达式如下：

![](/img/in-post/2018-03-16-PCI-chapter4-2-net2-detail.jpg)



### 3、反向传播法
反向传播（英语：Backpropagation，缩写为BP）是“误差反向传播”的简称，是一种与最优化方法（如梯度下降法）结合使用的，用来训练人工神经网络的常见方法。该方法对网络中所有权重计算损失函数的梯度。这个梯度会反馈给最优化方法，用来更新权值以最小化损失函数。

反向传播要求有对每个输入值想得到的已知输出，来计算损失函数梯度。因此，它通常被认为是一种监督式学习方法，虽然它也用在一些无监督网络（如自动编码器）中。它是多层前馈网络的Delta规则的推广，可以用链式法则对每层迭代计算梯度。反向传播要求人工神经元（或“节点”）的激励函数可微。





## 三、参考
[感知机](http://www.hankcs.com/ml/the-perceptron.html)

[从M-P神经元模型到感知机](https://xueqiu.com/3993902801/83328505)

[感知机-维基百科](https://zh.wikipedia.org/wiki/%E6%84%9F%E7%9F%A5%E5%99%A8)
[人工神经网络-维基百科](https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)
[反向传播算法-维基百科](https://zh.wikipedia.org/wiki/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95)

[技术向：一文读懂卷积神经网络CNN](http://www.cnblogs.com/nsnow/p/4562308.html)

[神经网络中前向传播和反向传播解析](https://blog.csdn.net/lhanchao/article/details/51419150)

[集体智慧编程第四章](https://blog.csdn.net/gavin_yueyi/article/details/49028315)

## 四、问题
损失函数：均方误差？还是[感知机](http://www.hankcs.com/ml/the-perceptron.html)的损失函数 ([感知机-维基百科](https://zh.wikipedia.org/wiki/%E6%84%9F%E7%9F%A5%E5%99%A8)里的准则函数)？

好吧，两个是一样的

感知机的学习算法：[感知机-维基百科](https://zh.wikipedia.org/wiki/%E6%84%9F%E7%9F%A5%E5%99%A8)里的学习算法？ 还是《统计学习方法》[感知机](http://www.hankcs.com/ml/the-perceptron.html)的学习算法
